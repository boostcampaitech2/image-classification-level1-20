{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "resnet18_pretrained = models.resnet18(pretrained=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "num_classes= 18\n",
    "num_ftrs = resnet18_pretrained.fc.in_features\n",
    "resnet18_pretrained.fc = nn.Linear(num_ftrs, num_classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import json\n",
    "with open(\"train.json\", \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "json_data = json_data['train']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform, json_data):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        self.json_data = json_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = json_data[index//7]['img'][index%7]['class']\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "class TrainDataset_60(Dataset):\n",
    "    def __init__(self, img_paths, transform, json_data):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        self.json_data = json_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if 'incorrect_mask.jpg' == self.img_paths[index].split('/')[-1]:\n",
    "            if 'female' in self.img_paths[index].split('/')[-2]:\n",
    "                label = 11\n",
    "            else:\n",
    "                label = 8\n",
    "        elif 'mask' in self.img_paths[index].split('/')[-1]:\n",
    "            if 'female' in self.img_paths[index].split('/')[-2]:\n",
    "                label = 5\n",
    "            else:\n",
    "                label = 2\n",
    "        else:\n",
    "            if 'female' in self.img_paths[index].split('/')[-2]:\n",
    "                label = 17\n",
    "            else:\n",
    "                label = 4\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 중앙을 중심으로 지킬앤 하이드 처럼 좌우에 컷믹스\n",
    "def rand_bbox(size, lam):\n",
    "    H = size[2]\n",
    "    W = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "\n",
    "    cx = np.random.randn() + W//2\n",
    "    cy = np.random.randn() + H//2\n",
    "\n",
    "    # 패치의 4점\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W//2)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W//2)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return int(bbx1), int(bby1), int(bbx2), int(bby2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from math import gcd\n",
    "gcd(len(image_paths), len(paths_60))\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "path_dir = 'input/data/train/images'\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = []\n",
    "for image in json_data:\n",
    "    for img in image['img']:\n",
    "        image_paths.append(img['path'])\n",
    "\n",
    "paths_60 = []\n",
    "for image in json_data:\n",
    "    for img in image['img']:\n",
    "        if img['class'] == 2 or img['class'] == 5 or img['class'] == 8 or img['class'] == 11 or img['class'] == 14 or img['class'] == 17:\n",
    "            paths_60.append(img['path'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TrainDataset(image_paths, transform, json_data)\n",
    "dataset_60 = TrainDataset_60(paths_60, transform, json_data)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=84, # \n",
    "    shuffle=True # shuffle 추가\n",
    ")\n",
    "\n",
    "loader2 = DataLoader(\n",
    "    dataset_60,\n",
    "    batch_size=84,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "device = torch.device('cuda')\n",
    "model = resnet18_pretrained.to(device)\n",
    "model.train()\n",
    "\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "for epoch in range(50):\n",
    "    running_loss = 0.0\n",
    "    epoch_f1 = 0\n",
    "    n_iter = 0\n",
    "    for (i, data), (j, data_60) in zip(enumerate(loader, 0),cycle(enumerate(loader2, 0))):\n",
    "        print(i, j)\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        inputs_60, labels_60 = data_60\n",
    "        inputs_60 = inputs_60.to(device)\n",
    "        labels_60 = labels_60.to(device)\n",
    "        \n",
    "        # t_ = torch.zeros((100,18))\n",
    "        # t_[range(100),labels]=1\n",
    "        # print(t_)\n",
    "        # t_ = t_.to(device)\n",
    "        # 일정 확률로 컷믹스\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if np.random.random() > 0.5 :\n",
    "            rand_index = torch.randperm(inputs_60.size()[0]) # 패치에 사용할 label\n",
    "            target_a = labels # 원본 이미지 label\n",
    "            target_b = labels_60[rand_index] # 패치 이미지 label  \n",
    "            lam = np.random.beta(1.0, 1.0)     \n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs_60.size(), lam)\n",
    "\n",
    "                # 원본 데이터에 컷믹스 패치\n",
    "            inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs_60[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "                # 원본 이미지와 패치 이미지의 넓이 비율\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "\n",
    "                # 예측은 레이블 1개\n",
    "            outputs = model(inputs)\n",
    "\n",
    "                # 원본 이미지의 레이블과 패치 이미지의 레이블에 대해 loss 가중합\n",
    "            loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam)\n",
    "            \n",
    "            # 컷믹스 안하면 그냥 별거 없음\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            print('{},{:.5f} loss: {:.3f}'.format(epoch+1, i+1, running_loss/10))\n",
    "            running_loss=0.0\n",
    "        n_iter += 1\n",
    "    print('Finished')\n",
    "    print('{:.4f}'.format(epoch_f1))\n",
    "\n",
    "torch.save(model.state_dict(), '/opt/ml/resnet_cutmix_60.pt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "1,10.00000 loss: 0.774\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 0\n",
      "17 1\n",
      "18 2\n",
      "19 3\n",
      "1,20.00000 loss: 0.534\n",
      "20 4\n",
      "21 5\n",
      "22 6\n",
      "23 7\n",
      "24 8\n",
      "25 9\n",
      "26 10\n",
      "27 11\n",
      "28 12\n",
      "29 13\n",
      "1,30.00000 loss: 0.509\n",
      "30 14\n",
      "31 15\n",
      "32 0\n",
      "33 1\n",
      "34 2\n",
      "35 3\n",
      "36 4\n",
      "37 5\n",
      "38 6\n",
      "39 7\n",
      "1,40.00000 loss: 0.406\n",
      "40 8\n",
      "41 9\n",
      "42 10\n",
      "43 11\n",
      "44 12\n",
      "45 13\n",
      "46 14\n",
      "47 15\n",
      "48 0\n",
      "49 1\n",
      "1,50.00000 loss: 0.402\n",
      "50 2\n",
      "51 3\n",
      "52 4\n",
      "53 5\n",
      "54 6\n",
      "55 7\n",
      "56 8\n",
      "57 9\n",
      "58 10\n",
      "59 11\n",
      "1,60.00000 loss: 0.485\n",
      "60 12\n",
      "61 13\n",
      "62 14\n",
      "63 15\n",
      "64 0\n",
      "65 1\n",
      "66 2\n",
      "67 3\n",
      "68 4\n",
      "69 5\n",
      "1,70.00000 loss: 0.478\n",
      "70 6\n",
      "71 7\n",
      "72 8\n",
      "73 9\n",
      "74 10\n",
      "75 11\n",
      "76 12\n",
      "77 13\n",
      "78 14\n",
      "79 15\n",
      "1,80.00000 loss: 0.392\n",
      "80 0\n",
      "81 1\n",
      "82 2\n",
      "83 3\n",
      "84 4\n",
      "85 5\n",
      "86 6\n",
      "87 7\n",
      "88 8\n",
      "89 9\n",
      "1,90.00000 loss: 0.452\n",
      "90 10\n",
      "91 11\n",
      "92 12\n",
      "93 13\n",
      "94 14\n",
      "95 15\n",
      "96 0\n",
      "97 1\n",
      "98 2\n",
      "99 3\n",
      "1,100.00000 loss: 0.500\n",
      "100 4\n",
      "101 5\n",
      "102 6\n",
      "103 7\n",
      "104 8\n",
      "105 9\n",
      "106 10\n",
      "107 11\n",
      "108 12\n",
      "109 13\n",
      "1,110.00000 loss: 0.437\n",
      "110 14\n",
      "111 15\n",
      "112 0\n",
      "113 1\n",
      "114 2\n",
      "115 3\n",
      "116 4\n",
      "117 5\n",
      "118 6\n",
      "119 7\n",
      "1,120.00000 loss: 0.456\n",
      "120 8\n",
      "121 9\n",
      "122 10\n",
      "123 11\n",
      "124 12\n",
      "125 13\n",
      "126 14\n",
      "127 15\n",
      "128 0\n",
      "129 1\n",
      "1,130.00000 loss: 0.403\n",
      "130 2\n",
      "131 3\n",
      "132 4\n",
      "133 5\n",
      "134 6\n",
      "135 7\n",
      "136 8\n",
      "137 9\n",
      "138 10\n",
      "139 11\n",
      "1,140.00000 loss: 0.399\n",
      "140 12\n",
      "141 13\n",
      "142 14\n",
      "143 15\n",
      "144 0\n",
      "145 1\n",
      "146 2\n",
      "147 3\n",
      "148 4\n",
      "149 5\n",
      "1,150.00000 loss: 0.428\n",
      "150 6\n",
      "151 7\n",
      "152 8\n",
      "153 9\n",
      "154 10\n",
      "155 11\n",
      "156 12\n",
      "157 13\n",
      "158 14\n",
      "159 15\n",
      "1,160.00000 loss: 0.412\n",
      "160 0\n",
      "161 1\n",
      "162 2\n",
      "163 3\n",
      "164 4\n",
      "165 5\n",
      "166 6\n",
      "167 7\n",
      "168 8\n",
      "169 9\n",
      "1,170.00000 loss: 0.384\n",
      "170 10\n",
      "171 11\n",
      "172 12\n",
      "173 13\n",
      "174 14\n",
      "175 15\n",
      "176 0\n",
      "177 1\n",
      "178 2\n",
      "179 3\n",
      "1,180.00000 loss: 0.445\n",
      "180 4\n",
      "181 5\n",
      "182 6\n",
      "183 7\n",
      "184 8\n",
      "185 9\n",
      "186 10\n",
      "187 11\n",
      "188 12\n",
      "189 13\n",
      "1,190.00000 loss: 0.378\n",
      "190 14\n",
      "191 15\n",
      "192 0\n",
      "193 1\n",
      "194 2\n",
      "195 3\n",
      "196 4\n",
      "197 5\n",
      "198 6\n",
      "199 7\n",
      "1,200.00000 loss: 0.388\n",
      "200 8\n",
      "201 9\n",
      "202 10\n",
      "203 11\n",
      "204 12\n",
      "205 13\n",
      "206 14\n",
      "207 15\n",
      "208 0\n",
      "209 1\n",
      "1,210.00000 loss: 0.300\n",
      "210 2\n",
      "211 3\n",
      "212 4\n",
      "213 5\n",
      "214 6\n",
      "215 7\n",
      "216 8\n",
      "217 9\n",
      "218 10\n",
      "219 11\n",
      "1,220.00000 loss: 0.394\n",
      "220 12\n",
      "221 13\n",
      "222 14\n",
      "223 15\n",
      "224 0\n",
      "Finished\n",
      "0.0000\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "2,10.00000 loss: 0.343\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 0\n",
      "17 1\n",
      "18 2\n",
      "19 3\n",
      "2,20.00000 loss: 0.371\n",
      "20 4\n",
      "21 5\n",
      "22 6\n",
      "23 7\n",
      "24 8\n",
      "25 9\n",
      "26 10\n",
      "27 11\n",
      "28 12\n",
      "29 13\n",
      "2,30.00000 loss: 0.356\n",
      "30 14\n",
      "31 15\n",
      "32 0\n",
      "33 1\n",
      "34 2\n",
      "35 3\n",
      "36 4\n",
      "37 5\n",
      "38 6\n",
      "39 7\n",
      "2,40.00000 loss: 0.318\n",
      "40 8\n",
      "41 9\n",
      "42 10\n",
      "43 11\n",
      "44 12\n",
      "45 13\n",
      "46 14\n",
      "47 15\n",
      "48 0\n",
      "49 1\n",
      "2,50.00000 loss: 0.307\n",
      "50 2\n",
      "51 3\n",
      "52 4\n",
      "53 5\n",
      "54 6\n",
      "55 7\n",
      "56 8\n",
      "57 9\n",
      "58 10\n",
      "59 11\n",
      "2,60.00000 loss: 0.264\n",
      "60 12\n",
      "61 13\n",
      "62 14\n",
      "63 15\n",
      "64 0\n",
      "65 1\n",
      "66 2\n",
      "67 3\n",
      "68 4\n",
      "69 5\n",
      "2,70.00000 loss: 0.240\n",
      "70 6\n",
      "71 7\n",
      "72 8\n",
      "73 9\n",
      "74 10\n",
      "75 11\n",
      "76 12\n",
      "77 13\n",
      "78 14\n",
      "79 15\n",
      "2,80.00000 loss: 0.297\n",
      "80 0\n",
      "81 1\n",
      "82 2\n",
      "83 3\n",
      "84 4\n",
      "85 5\n",
      "86 6\n",
      "87 7\n",
      "88 8\n",
      "89 9\n",
      "2,90.00000 loss: 0.328\n",
      "90 10\n",
      "91 11\n",
      "92 12\n",
      "93 13\n",
      "94 14\n",
      "95 15\n",
      "96 0\n",
      "97 1\n",
      "98 2\n",
      "99 3\n",
      "2,100.00000 loss: 0.338\n",
      "100 4\n",
      "101 5\n",
      "102 6\n",
      "103 7\n",
      "104 8\n",
      "105 9\n",
      "106 10\n",
      "107 11\n",
      "108 12\n",
      "109 13\n",
      "2,110.00000 loss: 0.313\n",
      "110 14\n",
      "111 15\n",
      "112 0\n",
      "113 1\n",
      "114 2\n",
      "115 3\n",
      "116 4\n",
      "117 5\n",
      "118 6\n",
      "119 7\n",
      "2,120.00000 loss: 0.313\n",
      "120 8\n",
      "121 9\n",
      "122 10\n",
      "123 11\n",
      "124 12\n",
      "125 13\n",
      "126 14\n",
      "127 15\n",
      "128 0\n",
      "129 1\n",
      "2,130.00000 loss: 0.295\n",
      "130 2\n",
      "131 3\n",
      "132 4\n",
      "133 5\n",
      "134 6\n",
      "135 7\n",
      "136 8\n",
      "137 9\n",
      "138 10\n",
      "139 11\n",
      "2,140.00000 loss: 0.322\n",
      "140 12\n",
      "141 13\n",
      "142 14\n",
      "143 15\n",
      "144 0\n",
      "145 1\n",
      "146 2\n",
      "147 3\n",
      "148 4\n",
      "149 5\n",
      "2,150.00000 loss: 0.328\n",
      "150 6\n",
      "151 7\n",
      "152 8\n",
      "153 9\n",
      "154 10\n",
      "155 11\n",
      "156 12\n",
      "157 13\n",
      "158 14\n",
      "159 15\n",
      "2,160.00000 loss: 0.273\n",
      "160 0\n",
      "161 1\n",
      "162 2\n",
      "163 3\n",
      "164 4\n",
      "165 5\n",
      "166 6\n",
      "167 7\n",
      "168 8\n",
      "169 9\n",
      "2,170.00000 loss: 0.289\n",
      "170 10\n",
      "171 11\n",
      "172 12\n",
      "173 13\n",
      "174 14\n",
      "175 15\n",
      "176 0\n",
      "177 1\n",
      "178 2\n",
      "179 3\n",
      "2,180.00000 loss: 0.348\n",
      "180 4\n",
      "181 5\n",
      "182 6\n",
      "183 7\n",
      "184 8\n",
      "185 9\n",
      "186 10\n",
      "187 11\n",
      "188 12\n",
      "189 13\n",
      "2,190.00000 loss: 0.333\n",
      "190 14\n",
      "191 15\n",
      "192 0\n",
      "193 1\n",
      "194 2\n",
      "195 3\n",
      "196 4\n",
      "197 5\n",
      "198 6\n",
      "199 7\n",
      "2,200.00000 loss: 0.315\n",
      "200 8\n",
      "201 9\n",
      "202 10\n",
      "203 11\n",
      "204 12\n",
      "205 13\n",
      "206 14\n",
      "207 15\n",
      "208 0\n",
      "209 1\n",
      "2,210.00000 loss: 0.322\n",
      "210 2\n",
      "211 3\n",
      "212 4\n",
      "213 5\n",
      "214 6\n",
      "215 7\n",
      "216 8\n",
      "217 9\n",
      "218 10\n",
      "219 11\n",
      "2,220.00000 loss: 0.338\n",
      "220 12\n",
      "221 13\n",
      "222 14\n",
      "223 15\n",
      "224 0\n",
      "Finished\n",
      "0.0000\n",
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "3,10.00000 loss: 0.266\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 0\n",
      "17 1\n",
      "18 2\n",
      "19 3\n",
      "3,20.00000 loss: 0.285\n",
      "20 4\n",
      "21 5\n",
      "22 6\n",
      "23 7\n",
      "24 8\n",
      "25 9\n",
      "26 10\n",
      "27 11\n",
      "28 12\n",
      "29 13\n",
      "3,30.00000 loss: 0.240\n",
      "30 14\n",
      "31 15\n",
      "32 0\n",
      "33 1\n",
      "34 2\n",
      "35 3\n",
      "36 4\n",
      "37 5\n",
      "38 6\n",
      "39 7\n",
      "3,40.00000 loss: 0.238\n",
      "40 8\n",
      "41 9\n",
      "42 10\n",
      "43 11\n",
      "44 12\n",
      "45 13\n",
      "46 14\n",
      "47 15\n",
      "48 0\n",
      "49 1\n",
      "3,50.00000 loss: 0.248\n",
      "50 2\n",
      "51 3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'batch_84_RANDOM_epoch_100_resnet_18_cutmix_60.csv'), index=False)\n",
    "\n",
    "print('test inference is done!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}