{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libray required"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "from PIL import Image\r\n",
    "import tqdm\r\n",
    "import timm\r\n",
    "\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import torchvision\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check version and Set Seed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\r\n",
    "# print (\"PyTorch version:[%s].\"%((###### ).__version__))\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #'cuda:0'\r\n",
    "print (\"device:[%s].\"%(device))\r\n",
    "\r\n",
    "def set_seed(random_seed):\r\n",
    "    torch.manual_seed(random_seed)\r\n",
    "    torch.cuda.manual_seed(random_seed)\r\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\r\n",
    "    torch.backends.cudnn.deterministic = True\r\n",
    "    torch.backends.cudnn.benchmark = False\r\n",
    "    np.random.seed(random_seed)\r\n",
    "    random.seed(random_seed)\r\n",
    "    \r\n",
    "set_seed(42)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PyTorch version:[1.7.1].\n",
      "device:[cuda].\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configuration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Face Crop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "!pip install facenet_pytorch\r\n",
    "from facenet_pytorch import MTCNN\r\n",
    "\r\n",
    "mtcnn = MTCNN(keep_all = True, device = device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: facenet_pytorch in /opt/conda/lib/python3.8/site-packages (2.5.2)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from facenet_pytorch) (8.1.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from facenet_pytorch) (2.24.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from facenet_pytorch) (0.8.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from facenet_pytorch) (1.19.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->facenet_pytorch) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->facenet_pytorch) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->facenet_pytorch) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->facenet_pytorch) (2.10)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from torchvision->facenet_pytorch) (1.7.1)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch->torchvision->facenet_pytorch) (3.7.4.3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "class _FaceCrop():\r\n",
    "    '''\r\n",
    "    device : MTCNN에게 넘겨줄 device. 기본값은 cuda.\r\n",
    "    margin : int값을 받으며, mtcnn이 검출한 얼굴 좌표의 크기를 입력받은 값만큼 수정함. 기본값은 30\r\n",
    "    not_detected : 입력의 형태는 [x,y,w,h]이며, mtcnn이 얼굴을 검출하지 못했을 시 해당 입력 바탕으로 사진을 자름. 기본값은 [100,50,300,300]\r\n",
    "    input_shape : 입력의 형태는 [Height, Width]이며, input으로 들어가는 image의 shape. 기본값은 [512, 384]\r\n",
    "    output_shape : 입력의 형태는 [Height, Width]이며, output으로 나가는 image의 shape. 기본값은 [300, 300]\r\n",
    "    '''\r\n",
    "\r\n",
    "    def __init__(self, device=\"cuda\", margin=30, not_detected=[100, 50, 300, 300], input_shape=[384, 512], output_shape = [300,300]):\r\n",
    "\r\n",
    "        self.margin = margin\r\n",
    "\r\n",
    "        # 검출되지 않았을 경우 crop 좌표\r\n",
    "        self.not_detected = not_detected\r\n",
    "        self.x = self.not_detected[0]\r\n",
    "        self.y = self.not_detected[1]\r\n",
    "        self.w = self.not_detected[2]\r\n",
    "        self.h = self.not_detected[3]\r\n",
    "\r\n",
    "        # shape 정의\r\n",
    "        self.shape = input_shape\r\n",
    "        self.img_h = self.shape[0]\r\n",
    "        self.img_w = self.shape[1]\r\n",
    "\r\n",
    "        self.device = device\r\n",
    "        self.mtcnn = MTCNN(keep_all = True, device = self.device, margin = self.margin)\r\n",
    "        self.transform = torchvision.transforms.Resize(output_shape)\r\n",
    "\r\n",
    "    def __call__(self, img):\r\n",
    "\r\n",
    "        if isinstance(img, torch.Tensor):\r\n",
    "            img = img.permute(1,2,0)*255\r\n",
    "        else:\r\n",
    "            img = torchvision.transforms.ToTensor()(img).permute(1,2,0)*255\r\n",
    "\r\n",
    "        boxes, props = mtcnn.detect(img)\r\n",
    "        \r\n",
    "        if props[0] is not None: # 얼굴을 검출 했을 시 (min, max는 image boundary를 벗어났을 때를 대비)\r\n",
    "\r\n",
    "            ind = props.argmax()\r\n",
    "            box = boxes[ind]            \r\n",
    "\r\n",
    "            x_min = max(int(box[0]) - self.margin ,0)\r\n",
    "            y_min = max(int(box[1]) - self.margin ,0)\r\n",
    "            x_max = min(int(box[2]) + self.margin, self.img_w)\r\n",
    "            y_max = min(int(box[3]) + self.margin, self.img_h)\r\n",
    "\r\n",
    "        else: # 얼굴을 검출하지 못했을 시\r\n",
    "\r\n",
    "            x_min = self.x\r\n",
    "            y_min = self.y\r\n",
    "            x_max = self.x + self.w\r\n",
    "            y_max = self.y + self.h\r\n",
    "\r\n",
    "        img = img[y_min:y_max, x_min:x_max, :]/255\r\n",
    "        img = img.permute(2,0,1)\r\n",
    "\r\n",
    "        return self.transform(img)\r\n",
    "\r\n",
    "facecrop = _FaceCrop()\r\n",
    "\r\n",
    "def crop_collate(samples, resize = (300,300)):\r\n",
    "\r\n",
    "    X = [facecrop(sample[0]) for sample in samples]\r\n",
    "    y = [sample[1] for sample in samples]\r\n",
    "\r\n",
    "    X = torch.stack(X)\r\n",
    "    y = torch.LongTensor(y)\r\n",
    "\r\n",
    "    return X, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "source": [
    "class Dataset(torch.utils.data.Dataset):\r\n",
    "    def __init__(self,csv):\r\n",
    "        super().__init__()\r\n",
    "        self.path = pd.read_csv(csv).values[:,0]\r\n",
    "        self.class_ = pd.read_csv(csv).values[:,1]\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.path)\r\n",
    "\r\n",
    "    def __getitem__(self,idx):\r\n",
    "        img_path = self.path[idx]\r\n",
    "        img = Image.open(img_path).convert(\"RGB\")\r\n",
    "        img = torchvision.transforms.ToTensor()(img)\r\n",
    "        label = self.class_[idx]\r\n",
    "\r\n",
    "        return img, label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "dataset = Dataset(\"train_data_path_and_class.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset = dataset, shuffle = False, collate_fn = crop_collate, batch_size = 32)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}