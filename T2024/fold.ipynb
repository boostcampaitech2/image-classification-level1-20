{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "stratifiedKFold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import dataset.custom_dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "TRAIN_PATH = '/opt/ml/input/data/train/data.csv'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df = pd.read_csv(TRAIN_PATH, index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "\n",
    "\n",
    "for train_idx, test_idx in stratifiedKFold.split(df['path'],df['class']):\n",
    "    train_cls = [0 for _ in range(18)]\n",
    "    test_cls = [0 for _ in range(18)]\n",
    "    \n",
    "    for i in train_idx:\n",
    "        train_cls[int(df['class'].loc[i])] += 1\n",
    "    \n",
    "    for i in test_idx:\n",
    "        test_cls[int(df['class'].loc[i])] += 1\n",
    "    \n",
    "    print(train_cls, test_cls)\n",
    "    print(np.sum(train_cls), np.sum(test_cls))\n",
    "    \n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2216, 1636, 332, 2908, 3272, 436, 443, 327, 66, 582, 654, 88, 443, 328, 67, 581, 654, 87] [554, 409, 83, 727, 818, 109, 111, 82, 17, 145, 164, 21, 111, 81, 16, 146, 164, 22]\n",
      "[2216, 1636, 332, 2908, 3272, 436, 444, 327, 66, 581, 655, 87, 443, 327, 66, 582, 654, 88] [554, 409, 83, 727, 818, 109, 110, 82, 17, 146, 163, 22, 111, 82, 17, 145, 164, 21]\n",
      "[2216, 1636, 332, 2908, 3272, 436, 443, 327, 67, 581, 655, 87, 444, 327, 66, 582, 654, 87] [554, 409, 83, 727, 818, 109, 111, 82, 16, 146, 163, 22, 110, 82, 17, 145, 164, 22]\n",
      "[2216, 1636, 332, 2908, 3272, 436, 443, 327, 67, 582, 654, 87, 443, 327, 66, 582, 655, 87] [554, 409, 83, 727, 818, 109, 111, 82, 16, 145, 164, 22, 111, 82, 17, 145, 163, 22]\n",
      "[2216, 1636, 332, 2908, 3272, 436, 443, 328, 66, 582, 654, 87, 443, 327, 67, 581, 655, 87] [554, 409, 83, 727, 818, 109, 111, 81, 17, 145, 164, 22, 111, 82, 16, 146, 163, 22]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "for train_idx, test_idx in kfold.split(df['path'], df['class']):\n",
    "    train_cls = [0 for _ in range(18)]\n",
    "    test_cls = [0 for _ in range(18)]\n",
    "    \n",
    "    for i in train_idx:\n",
    "        train_cls[int(df['class'].loc[i])] += 1\n",
    "    \n",
    "    for i in test_idx:\n",
    "        test_cls[int(df['class'].loc[i])] += 1\n",
    "    \n",
    "    print(train_cls, test_cls)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2212, 1613, 338, 2913, 3278, 445, 451, 329, 65, 572, 643, 86, 446, 333, 60, 589, 664, 83] [558, 432, 77, 722, 812, 100, 103, 80, 18, 155, 175, 23, 108, 76, 23, 138, 154, 26]\n",
      "[2214, 1660, 317, 2885, 3260, 446, 449, 338, 66, 588, 650, 85, 449, 328, 68, 570, 664, 83] [556, 385, 98, 750, 830, 99, 105, 71, 17, 139, 168, 24, 105, 81, 15, 157, 154, 26]\n",
      "[2207, 1637, 337, 2935, 3303, 409, 449, 318, 63, 587, 640, 89, 428, 329, 70, 568, 655, 96] [563, 408, 78, 700, 787, 136, 105, 91, 20, 140, 178, 20, 126, 80, 13, 159, 163, 13]\n",
      "[2219, 1648, 332, 2935, 3235, 435, 440, 327, 67, 580, 656, 85, 450, 320, 68, 595, 644, 84] [551, 397, 83, 700, 855, 110, 114, 82, 16, 147, 162, 24, 104, 89, 15, 132, 174, 25]\n",
      "[2228, 1622, 336, 2872, 3284, 445, 427, 324, 71, 581, 683, 91, 443, 326, 66, 586, 645, 90] [542, 423, 79, 763, 806, 100, 127, 85, 12, 146, 135, 18, 111, 83, 17, 141, 173, 19]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from mlp_mixer_pytorch import MLPMixer\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "device = torch.device('cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "model = MLPMixer(\n",
    "    image_size = 384,\n",
    "    channels = 3,\n",
    "    patch_size = 16,\n",
    "    dim = 512,\n",
    "    depth = 12,\n",
    "    num_classes = 18\n",
    ").to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "NUM_EPOCHS = 30\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 384), Image.BILINEAR),\n",
    "    transforms.CenterCrop(384),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    for index, (train_idx, val_idx) in enumerate(kfold.split(df['path'],df['class'])):\n",
    "        df_train = pd.DataFrame(columns=['path','class'])\n",
    "        for i in train_idx:\n",
    "            df_train = df_train.append({'path':df['path'].loc[i], 'class':df['class'].loc[i]}, ignore_index=True)\n",
    "        \n",
    "        df_val = pd.DataFrame(columns=['path','class'])\n",
    "        for i in val_idx:\n",
    "            df_val = df_val.append({'path':df['path'].loc[i], 'class':df['class'].loc[i]}, ignore_index=True)\n",
    "\n",
    "        train_set = dataset.custom_dataset.Custom_Dataset(df_train, target='class', transforms=transform, train=True)\n",
    "        val_set = dataset.custom_dataset.Custom_Dataset(df_val, target='class', transforms=transform, train=True)\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=32, num_workers=4)\n",
    "        val_loader = DataLoader(val_set, batch_size=32, num_workers=4)\n",
    "\n",
    "        for s in ['train', 'validation']:\n",
    "            if s == 'train':\n",
    "                model.train()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_acc = 0.0\n",
    "                n_iter = 0\n",
    "                epoch_f1 = 0.0\n",
    "\n",
    "                for index, (images, labels) in enumerate(train_loader):\n",
    "                    images = images.to(device)\n",
    "                    target = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model(images)\n",
    "                    _, preds = torch.max(logits, 1)\n",
    "                    loss = criterion(logits, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * images.size(0)\n",
    "                    running_acc += torch.sum(preds == target.data)\n",
    "                    epoch_f1 += f1_score(target.cpu().numpy(), preds.cpu().numpy(), average='macro')\n",
    "                    n_iter += 1\n",
    "                \n",
    "                epoch_loss = running_loss / len(train_loader.dataset)\n",
    "                epoch_acc = running_acc / len(train_loader.dataset)\n",
    "                epoch_f1 = epoch_f1/n_iter\n",
    "\n",
    "                print(f\"Epoch: {epoch} -  Loss : {epoch_loss:.3f},  Accuracy : {epoch_acc:.3f},  F1-Score : {epoch_f1:.4f}\")\n",
    "\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "\n",
    "                    val_loss_items = []\n",
    "                    val_acc_items = []\n",
    "                    val_f1_score = 0.0\n",
    "                    v_iter = 0\n",
    "\n",
    "                    for val_batch in val_loader:\n",
    "                        inputs, labels = val_batch\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "\n",
    "                        outs = model(inputs)\n",
    "                        preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "                        loss_item = criterion(outs, labels).item()\n",
    "                        acc_item = (labels == preds).sum().item()\n",
    "\n",
    "                        val_loss_items.append(loss_item)\n",
    "                        val_acc_items.append(acc_item)\n",
    "                        val_f1_score += f1_score(labels.cpu().numpy(), preds.cpu().numpy(), average='micro')\n",
    "                        v_iter += 1\n",
    "\n",
    "                    val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "                    val_acc = np.sum(val_acc_items) / len(val_set)\n",
    "                    val_f1 = np.sum(val_f1_score) / v_iter\n",
    "        \n",
    "                print(f'val_acc : {val_acc:.3f}, val loss : {val_loss:.3f}, val f1 : {val_f1:.3f}')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ce1233e594e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}